{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by inês <3 doing my best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Close_Ratio_2</th>\n",
       "      <th>Trend_2</th>\n",
       "      <th>Close_Ratio_5</th>\n",
       "      <th>Trend_5</th>\n",
       "      <th>Close_Ratio_60</th>\n",
       "      <th>Trend_60</th>\n",
       "      <th>Close_Ratio_250</th>\n",
       "      <th>Trend_250</th>\n",
       "      <th>EMA</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-12-31 00:00:00+00:00</th>\n",
       "      <td>0.997801</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>1.010544</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>1.111599</td>\n",
       "      <td>0.205692</td>\n",
       "      <td>1.306845</td>\n",
       "      <td>0.375537</td>\n",
       "      <td>32.405042</td>\n",
       "      <td>47.505236</td>\n",
       "      <td>-0.004389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03 00:00:00+00:00</th>\n",
       "      <td>0.999019</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>1.004139</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>1.105802</td>\n",
       "      <td>0.203945</td>\n",
       "      <td>1.302827</td>\n",
       "      <td>0.358348</td>\n",
       "      <td>32.456154</td>\n",
       "      <td>62.631046</td>\n",
       "      <td>-0.001960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04 00:00:00+00:00</th>\n",
       "      <td>0.985056</td>\n",
       "      <td>-0.006349</td>\n",
       "      <td>0.974955</td>\n",
       "      <td>0.022493</td>\n",
       "      <td>1.070865</td>\n",
       "      <td>0.212289</td>\n",
       "      <td>1.263257</td>\n",
       "      <td>0.332691</td>\n",
       "      <td>32.351091</td>\n",
       "      <td>42.035479</td>\n",
       "      <td>-0.029447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05 00:00:00+00:00</th>\n",
       "      <td>0.998354</td>\n",
       "      <td>-0.031407</td>\n",
       "      <td>0.977872</td>\n",
       "      <td>-0.001184</td>\n",
       "      <td>1.064969</td>\n",
       "      <td>0.149825</td>\n",
       "      <td>1.258187</td>\n",
       "      <td>0.300775</td>\n",
       "      <td>32.246122</td>\n",
       "      <td>44.496629</td>\n",
       "      <td>-0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06 00:00:00+00:00</th>\n",
       "      <td>0.984544</td>\n",
       "      <td>-0.032735</td>\n",
       "      <td>0.961412</td>\n",
       "      <td>-0.031219</td>\n",
       "      <td>1.030942</td>\n",
       "      <td>0.151433</td>\n",
       "      <td>1.219133</td>\n",
       "      <td>0.246995</td>\n",
       "      <td>32.008987</td>\n",
       "      <td>31.477881</td>\n",
       "      <td>-0.030442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24 00:00:00+00:00</th>\n",
       "      <td>1.021212</td>\n",
       "      <td>0.038810</td>\n",
       "      <td>1.059307</td>\n",
       "      <td>0.052673</td>\n",
       "      <td>1.006141</td>\n",
       "      <td>-0.122418</td>\n",
       "      <td>1.025281</td>\n",
       "      <td>-0.039847</td>\n",
       "      <td>34.351221</td>\n",
       "      <td>56.022427</td>\n",
       "      <td>0.043343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25 00:00:00+00:00</th>\n",
       "      <td>1.002303</td>\n",
       "      <td>0.068611</td>\n",
       "      <td>1.042077</td>\n",
       "      <td>0.104073</td>\n",
       "      <td>1.011902</td>\n",
       "      <td>-0.056044</td>\n",
       "      <td>1.030389</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>34.670686</td>\n",
       "      <td>63.664102</td>\n",
       "      <td>0.004616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26 00:00:00+00:00</th>\n",
       "      <td>1.007111</td>\n",
       "      <td>0.047959</td>\n",
       "      <td>1.036225</td>\n",
       "      <td>0.106583</td>\n",
       "      <td>1.027201</td>\n",
       "      <td>-0.055231</td>\n",
       "      <td>1.045413</td>\n",
       "      <td>-0.020890</td>\n",
       "      <td>35.021279</td>\n",
       "      <td>73.667689</td>\n",
       "      <td>0.014324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29 00:00:00+00:00</th>\n",
       "      <td>0.995450</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>1.011422</td>\n",
       "      <td>0.101093</td>\n",
       "      <td>1.018814</td>\n",
       "      <td>-0.036361</td>\n",
       "      <td>1.036223</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>35.266437</td>\n",
       "      <td>74.840789</td>\n",
       "      <td>-0.009059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30 00:00:00+00:00</th>\n",
       "      <td>0.994865</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.992933</td>\n",
       "      <td>0.078492</td>\n",
       "      <td>1.009527</td>\n",
       "      <td>-0.043391</td>\n",
       "      <td>1.026056</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>35.416321</td>\n",
       "      <td>70.030582</td>\n",
       "      <td>-0.010218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3291 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                      Close_Ratio_2   Trend_2  Close_Ratio_5   Trend_5  \\\n",
       "Date                                                                          \n",
       "2010-12-31 00:00:00+00:00       0.997801  0.034612       1.010544  0.015206   \n",
       "2011-01-03 00:00:00+00:00       0.999019  0.003476       1.004139  0.013044   \n",
       "2011-01-04 00:00:00+00:00       0.985056 -0.006349       0.974955  0.022493   \n",
       "2011-01-05 00:00:00+00:00       0.998354 -0.031407       0.977872 -0.001184   \n",
       "2011-01-06 00:00:00+00:00       0.984544 -0.032735       0.961412 -0.031219   \n",
       "...                                  ...       ...            ...       ...   \n",
       "2024-01-24 00:00:00+00:00       1.021212  0.038810       1.059307  0.052673   \n",
       "2024-01-25 00:00:00+00:00       1.002303  0.068611       1.042077  0.104073   \n",
       "2024-01-26 00:00:00+00:00       1.007111  0.047959       1.036225  0.106583   \n",
       "2024-01-29 00:00:00+00:00       0.995450  0.018940       1.011422  0.101093   \n",
       "2024-01-30 00:00:00+00:00       0.994865  0.005265       0.992933  0.078492   \n",
       "\n",
       "Price                      Close_Ratio_60  Trend_60  Close_Ratio_250  \\\n",
       "Date                                                                   \n",
       "2010-12-31 00:00:00+00:00        1.111599  0.205692         1.306845   \n",
       "2011-01-03 00:00:00+00:00        1.105802  0.203945         1.302827   \n",
       "2011-01-04 00:00:00+00:00        1.070865  0.212289         1.263257   \n",
       "2011-01-05 00:00:00+00:00        1.064969  0.149825         1.258187   \n",
       "2011-01-06 00:00:00+00:00        1.030942  0.151433         1.219133   \n",
       "...                                   ...       ...              ...   \n",
       "2024-01-24 00:00:00+00:00        1.006141 -0.122418         1.025281   \n",
       "2024-01-25 00:00:00+00:00        1.011902 -0.056044         1.030389   \n",
       "2024-01-26 00:00:00+00:00        1.027201 -0.055231         1.045413   \n",
       "2024-01-29 00:00:00+00:00        1.018814 -0.036361         1.036223   \n",
       "2024-01-30 00:00:00+00:00        1.009527 -0.043391         1.026056   \n",
       "\n",
       "Price                      Trend_250        EMA        RSI    Target  \n",
       "Date                                                                  \n",
       "2010-12-31 00:00:00+00:00   0.375537  32.405042  47.505236 -0.004389  \n",
       "2011-01-03 00:00:00+00:00   0.358348  32.456154  62.631046 -0.001960  \n",
       "2011-01-04 00:00:00+00:00   0.332691  32.351091  42.035479 -0.029447  \n",
       "2011-01-05 00:00:00+00:00   0.300775  32.246122  44.496629 -0.003287  \n",
       "2011-01-06 00:00:00+00:00   0.246995  32.008987  31.477881 -0.030442  \n",
       "...                              ...        ...        ...       ...  \n",
       "2024-01-24 00:00:00+00:00  -0.039847  34.351221  56.022427  0.043343  \n",
       "2024-01-25 00:00:00+00:00  -0.001273  34.670686  63.664102  0.004616  \n",
       "2024-01-26 00:00:00+00:00  -0.020890  35.021279  73.667689  0.014324  \n",
       "2024-01-29 00:00:00+00:00   0.005142  35.266437  74.840789 -0.009059  \n",
       "2024-01-30 00:00:00+00:00   0.000525  35.416321  70.030582 -0.010218  \n",
       "\n",
       "[3291 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../../extra_features.pkl\")\n",
    "df.xs(\"HAL\", level='Ticker', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When determining the optimal training size for time series forecasting, a key consideration is the balance between the amount of historical data and the ability of the model to generalize effectively. Commonly, a \"window size\" is chosen, which refers to the number of past observations used to train a model before predicting future points. Research suggests that for time series data, particularly in volatile and unpredictable contexts, using a larger window (e.g., 70% of the data) can improve model performance as it captures enough historical context, but care must be taken to avoid overfitting to past patterns. For example, one approach using a sliding window technique with a 70% training size has been applied successfully, where data is divided into a training set and a test set based on this proportion.\n",
    "\n",
    "Furthermore, some studies suggest that using cross-validation methods like Time Series Split or Sliding Window cross-validation can provide better insights into model performance across different segments of the data. These methods test the model on multiple, time-sensitive segments and can help determine whether increasing the training size (or adjusting the window) consistently leads to improved predictions.\n",
    "\n",
    "In terms of practical implementation, experimenting with different window sizes (e.g., 60%, 70%, 80%) and horizons (e.g., predicting 5-day or 10-day ahead) is advised. Testing this across multiple time periods can also help ensure robustness, especially for volatile financial markets or stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(X, y, model, train_size=0.7, horizon=5):\n",
    "    n = len(y)\n",
    "    train_len = int(n * train_size)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(train_len, n, horizon):\n",
    "        # Create training and test sets\n",
    "        train_X, test_X = X[:i], X[i:i+horizon]\n",
    "        train_y, test_y = y[:i], y[i:i+horizon]\n",
    "        \n",
    "        # Fit model (for example, XGBoost)\n",
    "        model = XGBRegressor()  # Or any other model\n",
    "        model.fit(train_X, train_y)\n",
    "        \n",
    "        # Predict and evaluate performance\n",
    "        predictions = model.predict(test_X)\n",
    "        error = mean_squared_error(test_y, predictions)\n",
    "        \n",
    "        results.append(error)\n",
    "    \n",
    "    return np.mean(results), np.std(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Total number of rows**: 3291 rows (representing data from 2011 to 2024).\n",
    "2. **Training set size**: 70% of the total data. \n",
    "   - Training size = 0.70×3291 = 2303.7 ≈ 2304 rows.\n",
    "3. **Testing set size**: 5 rows for each test (since we want to predict 5 days ahead).\n",
    "   - Remaining data (for testing):  3291 - 2304 = 987 rows.\n",
    "   - Number of sets: $$ \\text{Number of test sets} = \\frac{987}{5} = 197.4 \\approx 197 $$ sets.\n",
    "\n",
    "### Final Calculation:\n",
    "- **Training set**: 2304 rows (70% of data).\n",
    "- **Test sets**: 197 sets, each containing 5 days of predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m\n\u001b[1;32m      5\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(XGBRegressor(), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[1;32m     19\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "\n",
    "    'max_depth': [3, 5, 7],\n",
    "\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(XGBRegressor(), param_grid, cv=3)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chang, V., Xu, Q.A., Chidozie, A. and Wang, H. (2024). Predicting Economic Trends and Stock Market Prices with Deep Learning and Advanced Machine Learning Techniques. Electronics, [online] 13(17), p.3396. doi:https://doi.org/10.3390/electronics13173396."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Github.io. (2022). Time Series Cross Validation — forecast-tools. [online] Available at: https://tommonks.github.io/forecast-tools/content/03_cross_validation.html [Accessed 5 Dec. 2024]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sharma, N. (2024). How to Use XGBoost for Time-Series Forecasting? [online] Analytics Vidhya. Available at: https://www.analyticsvidhya.com/blog/2024/01/xgboost-for-time-series-forecasting/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
